{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc92389",
   "metadata": {},
   "source": [
    "# Maximum Likelihood Estimation (MLE) Tutorial\n",
    "This notebook demonstrates maximum likelihood estimation (MLE) using Python code written from scratch. We will estimate the parameters of a normal distribution (mean and variance) using MLE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33caad46",
   "metadata": {},
   "source": [
    "## 1. Method Overview\n",
    "\n",
    "**What is Maximum Likelihood Estimation?**\n",
    "\n",
    "Maximum Likelihood Estimation is a statistical method used to estimate the parameters of a probability distribution given observed data. The main idea is to find the set of parameters that makes the observed data most probable.\n",
    "\n",
    "**Key Concepts and Assumptions:**\n",
    "\n",
    "- **Likelihood Function:** For a given model, the likelihood function measures the probability of observing the data as a function of the model parameters.\n",
    "- **Log-Likelihood:** Since the likelihood can become a very small number when multiplied over many data points, it is common to work with the logarithm of the likelihood (which turns products into sums).\n",
    "- **Assumptions:**  \n",
    "  - The data points are assumed to be independent and identically distributed (i.i.d.).\n",
    "  - The chosen model (in our case, a normal distribution) is assumed to be appropriate for the data.\n",
    "\n",
    "**When is MLE Useful?**\n",
    "\n",
    "MLE is widely used in statistics for parameter estimation because it has several desirable properties (consistency, efficiency, asymptotic normality) under general conditions. It is particularly useful when you have a parametric model and want to fit it to observed data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ddd0a",
   "metadata": {},
   "source": [
    "## 2. Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a7bc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c86e339",
   "metadata": {},
   "source": [
    "## 3. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d4e41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood_normal(data, mu, sigma):\n",
    "    \"\"\"\n",
    "    Calculate the log-likelihood of data under a normal distribution.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: array-like, the observed data\n",
    "    - mu: float, the mean of the normal distribution\n",
    "    - sigma: float, the standard deviation of the normal distribution\n",
    "    \n",
    "    Returns:\n",
    "    - log_likelihood: float, the computed log-likelihood\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    # Avoid division by zero error if sigma is extremely small\n",
    "    if sigma <= 0:\n",
    "        return -np.inf\n",
    "    # Calculate each term of the log-likelihood\n",
    "    # log L = -n/2 * log(2*pi*sigma^2) - sum((data - mu)^2) / (2*sigma^2)\n",
    "    ll = -0.5 * n * np.log(2 * math.pi * sigma**2) - np.sum((data - mu)**2) / (2 * sigma**2)\n",
    "    return ll\n",
    "\n",
    "def mle_normal(data):\n",
    "    \"\"\"\n",
    "    Compute the Maximum Likelihood Estimates (MLE) for the mean and variance of a normal distribution.\n",
    "    \n",
    "    For the normal distribution, the MLE for the mean is the sample mean and for the variance is the sample variance.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: array-like, the observed data\n",
    "    \n",
    "    Returns:\n",
    "    - mu_hat: float, the estimated mean\n",
    "    - sigma_hat: float, the estimated standard deviation\n",
    "    \"\"\"\n",
    "    # MLE for mean is the sample average\n",
    "    mu_hat = np.mean(data)\n",
    "    # MLE for variance is the sample variance (using N instead of N-1 for MLE)\n",
    "    sigma_hat = np.sqrt(np.sum((data - mu_hat)**2) / len(data))\n",
    "    return mu_hat, sigma_hat\n",
    "\n",
    "def grid_search_mu(data, sigma_fixed, mu_range):\n",
    "    \"\"\"\n",
    "    Compute the log-likelihood for a range of mu values with a fixed sigma.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: array-like, the observed data\n",
    "    - sigma_fixed: float, fixed standard deviation value\n",
    "    - mu_range: array-like, a range of mu values to evaluate\n",
    "    \n",
    "    Returns:\n",
    "    - log_likelihoods: list of log-likelihood values corresponding to each mu\n",
    "    \"\"\"\n",
    "    log_likelihoods = []\n",
    "    for mu in mu_range:\n",
    "        ll = log_likelihood_normal(data, mu, sigma_fixed)\n",
    "        log_likelihoods.append(ll)\n",
    "    return log_likelihoods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ef9e4",
   "metadata": {},
   "source": [
    "## 4. Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f707a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data from a normal distribution with known parameters\n",
    "np.random.seed(42)  # For reproducibility\n",
    "mu_true = 5.0\n",
    "sigma_true = 2.0\n",
    "n_samples = 500\n",
    "data = np.random.normal(loc=mu_true, scale=sigma_true, size=n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655cb94e",
   "metadata": {},
   "source": [
    "## 5. Parameter Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b8ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MLE estimates using the analytical solutions\n",
    "mu_hat, sigma_hat = mle_normal(data)\n",
    "\n",
    "# Print out the estimated parameters\n",
    "print(\"True parameters:\")\n",
    "print(\"Mean (mu_true):\", mu_true)\n",
    "print(\"Standard Deviation (sigma_true):\", sigma_true)\n",
    "print(\"\\nMLE estimates:\")\n",
    "print(\"Estimated Mean (mu_hat):\", mu_hat)\n",
    "print(\"Estimated Standard Deviation (sigma_hat):\", sigma_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d7565f",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61250e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram of the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "count, bins, ignored = plt.hist(data, bins=30, density=True, alpha=0.6, color='g', label='Data Histogram')\n",
    "\n",
    "# Plot the true normal distribution\n",
    "x = np.linspace(min(data), max(data), 1000)\n",
    "true_pdf = (1/(sigma_true * np.sqrt(2 * math.pi))) * np.exp(-0.5 * ((x - mu_true)/sigma_true)**2)\n",
    "plt.plot(x, true_pdf, 'b', linewidth=2, label='True Distribution')\n",
    "\n",
    "# Plot the estimated normal distribution from MLE estimates\n",
    "estimated_pdf = (1/(sigma_hat * np.sqrt(2 * math.pi))) * np.exp(-0.5 * ((x - mu_hat)/sigma_hat)**2)\n",
    "plt.plot(x, estimated_pdf, 'r--', linewidth=2, label='MLE Estimated Distribution')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Histogram of Data with True and MLE Estimated Normal Distributions')\n",
    "plt.xlabel('Data Value')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cc4e36",
   "metadata": {},
   "source": [
    "## 7. Log-likelihood Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a769325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot log-likelihood vs. mu for a fixed sigma (using the estimated sigma)\n",
    "mu_values = np.linspace(mu_hat - 3, mu_hat + 3, 300)\n",
    "ll_values = grid_search_mu(data, sigma_fixed=sigma_hat, mu_range=mu_values)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mu_values, ll_values, 'm-', linewidth=2)\n",
    "plt.title('Log-Likelihood as a Function of mu (sigma fixed at MLE estimate)')\n",
    "plt.xlabel('mu')\n",
    "plt.ylabel('Log-Likelihood')\n",
    "plt.axvline(mu_hat, color='r', linestyle='--', label=f'MLE mu = {mu_hat:.2f}')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7917d33a",
   "metadata": {},
   "source": [
    "## 8. Analysis and Discussion\n",
    "\n",
    "The printed MLE estimates are very close to the true parameters we used to generate the data.\n",
    "The histogram along with the plotted curves shows:\n",
    "- The blue line represents the true normal distribution.\n",
    "- The red dashed line represents the estimated normal distribution using MLE.\n",
    "They overlap significantly, indicating that our MLE procedure correctly recovers the parameters.\n",
    "\n",
    "The log-likelihood plot as a function of mu (with sigma fixed at its MLE estimate) shows a clear maximum at the MLE of mu.\n",
    "This visual demonstration reinforces the concept that MLE seeks the parameter value that maximizes the likelihood of the observed data.\n",
    "\n",
    "**Potential Pitfalls & Limitations:**\n",
    "- MLE relies on the assumption that the chosen model is correct. If the true data generating process is different,\n",
    "  the MLE estimates may be misleading.\n",
    "- For more complex models, the likelihood function might be multi-modal, and optimization may require careful initialization.\n",
    "- Numerical optimization (if used) may be sensitive to step size and convergence criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310f2b7c",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this tutorial, we:\n",
    "- Introduced the method of Maximum Likelihood Estimation, including its purpose and key assumptions.\n",
    "- Implemented a full Python example from scratch to estimate the parameters of a normal distribution.\n",
    "- Generated synthetic data and used both analytical and visualization methods to validate our estimates.\n",
    "- Discussed the results and potential challenges when applying MLE.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- MLE provides a principled way to estimate model parameters by maximizing the likelihood of the observed data.\n",
    "- In simple cases (like the normal distribution), analytical solutions exist and can be implemented directly.\n",
    "- Visualization (such as histogram overlays and log-likelihood curves) is a powerful tool to verify and interpret the results.\n",
    "\n",
    "This method can be extended to other parametric models, and the approach remains similar:\n",
    "define the likelihood, compute (or maximize) the log-likelihood, and interpret the results."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
