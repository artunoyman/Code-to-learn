{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb558881",
   "metadata": {},
   "source": [
    "# Anomaly Detection using Gaussian Distribution\n",
    "\n",
    "This notebook demonstrates the implementation of an anomaly detection system using Gaussian (Normal) distribution. Anomaly detection is widely used in various applications such as:\n",
    "- Fraud detection in financial transactions\n",
    "- Fault detection in manufacturing systems\n",
    "- Network intrusion detection\n",
    "- Health monitoring systems\n",
    "\n",
    "## Theory Overview\n",
    "The algorithm works by:\n",
    "1. Modeling the normal behavior of the system using Gaussian distribution\n",
    "2. Computing the probability of new examples\n",
    "3. Flagging examples with very low probability as anomalies\n",
    "\n",
    "The Gaussian distribution is characterized by two parameters:\n",
    "- μ (mu): mean of the distribution\n",
    "- σ² (sigma squared): variance of the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5119344d",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e434e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e1ab8",
   "metadata": {},
   "source": [
    "## 2. Data Generation\n",
    "\n",
    "We'll generate synthetic data with known anomalies to demonstrate the algorithm:\n",
    "- Normal data points will follow a Gaussian distribution\n",
    "- Anomalies will be generated from a different distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a596f11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate normal data\n",
    "n_normal = 1000\n",
    "normal_data = np.random.normal(loc=10, scale=2, size=(n_normal, 2))\n",
    "\n",
    "# Generate anomalies\n",
    "n_anomalies = 50\n",
    "anomalies = np.random.uniform(low=0, high=20, size=(n_anomalies, 2))\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(normal_data[:, 0], normal_data[:, 1], alpha=0.5, label='Normal Data')\n",
    "plt.scatter(anomalies[:, 0], anomalies[:, 1], c='red', alpha=0.7, label='Anomalies')\n",
    "plt.title('Generated Dataset with Normal Points and Anomalies')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26694f25",
   "metadata": {},
   "source": [
    "## 3. Implementing Gaussian Distribution Functions\n",
    "\n",
    "We'll implement functions to:\n",
    "1. Calculate parameters (μ, σ²) of the Gaussian distribution\n",
    "2. Compute probability density for new examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a98e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_gaussian_parameters(X):\n",
    "    \"\"\"\n",
    "    Estimates parameters for a Gaussian distribution\n",
    "    \n",
    "    Parameters:\n",
    "        X: numpy array of shape (m, n) where m is number of examples\n",
    "           and n is number of features\n",
    "    \n",
    "    Returns:\n",
    "        mu: numpy array of shape (n,) containing means of each feature\n",
    "        sigma2: numpy array of shape (n,) containing variances of each feature\n",
    "    \"\"\"\n",
    "    mu = np.mean(X, axis=0)\n",
    "    sigma2 = np.var(X, axis=0)\n",
    "    return mu, sigma2\n",
    "\n",
    "def compute_gaussian_probability(X, mu, sigma2):\n",
    "    \"\"\"\n",
    "    Computes probability density for each example under the Gaussian distribution\n",
    "    \n",
    "    Parameters:\n",
    "        X: numpy array of shape (m, n)\n",
    "        mu: numpy array of shape (n,)\n",
    "        sigma2: numpy array of shape (n,)\n",
    "    \n",
    "    Returns:\n",
    "        p: numpy array of shape (m,) containing probabilities\n",
    "    \"\"\"\n",
    "    k = len(mu)\n",
    "    \n",
    "    # Compute probability for each feature\n",
    "    p = np.ones((X.shape[0],))\n",
    "    for i in range(k):\n",
    "        p *= norm.pdf(X[:, i], mu[i], np.sqrt(sigma2[i]))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9638fb3d",
   "metadata": {},
   "source": [
    "## 4. Training the Model\n",
    "\n",
    "We'll:\n",
    "1. Estimate Gaussian parameters from normal data\n",
    "2. Find a good threshold for anomaly detection using a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3bd0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate parameters\n",
    "mu, sigma2 = estimate_gaussian_parameters(normal_data)\n",
    "\n",
    "# Compute probabilities for normal data and anomalies\n",
    "p_normal = compute_gaussian_probability(normal_data, mu, sigma2)\n",
    "p_anomaly = compute_gaussian_probability(anomalies, mu, sigma2)\n",
    "\n",
    "# Visualize probability distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(np.log(p_normal), bins=50, alpha=0.5, label='Normal Data')\n",
    "plt.hist(np.log(p_anomaly), bins=50, alpha=0.5, label='Anomalies')\n",
    "plt.title('Log Probability Distribution')\n",
    "plt.xlabel('Log Probability')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([np.log(p_normal), np.log(p_anomaly)], labels=['Normal', 'Anomaly'])\n",
    "plt.title('Log Probability Boxplot')\n",
    "plt.ylabel('Log Probability')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7f5682",
   "metadata": {},
   "source": [
    "## 5. Selecting the Anomaly Threshold\n",
    "\n",
    "We'll select a threshold that best separates normal data from anomalies. Points with probability below this threshold will be classified as anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927f01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_threshold(p_normal, p_anomaly):\n",
    "    \"\"\"\n",
    "    Selects the best threshold for anomaly detection\n",
    "    using F1 score as the metric\n",
    "    \"\"\"\n",
    "    best_f1 = 0\n",
    "    best_epsilon = 0\n",
    "    \n",
    "    # Try different thresholds\n",
    "    step = (np.max(np.log(p_normal)) - np.min(np.log(p_normal))) / 1000\n",
    "    for epsilon in np.arange(np.min(np.log(p_normal)), np.max(np.log(p_normal)), step):\n",
    "        # Convert to linear scale\n",
    "        eps = np.exp(epsilon)\n",
    "        \n",
    "        # Predict anomalies\n",
    "        predictions_normal = (p_normal < eps).astype(int)\n",
    "        predictions_anomaly = (p_anomaly < eps).astype(int)\n",
    "        \n",
    "        # Compute metrics\n",
    "        tp = np.sum(predictions_anomaly == 1)\n",
    "        fp = np.sum(predictions_normal == 1)\n",
    "        fn = np.sum(predictions_anomaly == 0)\n",
    "        \n",
    "        # Compute precision and recall\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        \n",
    "        # Compute F1 score\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        if f1 > best_f1:\n",
    "            best_f1 = f1\n",
    "            best_epsilon = eps\n",
    "    \n",
    "    return best_epsilon, best_f1\n",
    "\n",
    "# Find best threshold\n",
    "epsilon, f1_score = select_threshold(p_normal, p_anomaly)\n",
    "print(f'Best threshold: {epsilon:.6f}')\n",
    "print(f'F1 score: {f1_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f27a93",
   "metadata": {},
   "source": [
    "## 6. Visualizing Results\n",
    "\n",
    "Let's create a contour plot to visualize the decision boundary of our anomaly detection system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21465592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid of points\n",
    "x_min, x_max = min(min(normal_data[:, 0]), min(anomalies[:, 0])) - 1, max(max(normal_data[:, 0]), max(anomalies[:, 0])) + 1\n",
    "y_min, y_max = min(min(normal_data[:, 1]), min(anomalies[:, 1])) - 1, max(max(normal_data[:, 1]), max(anomalies[:, 1])) + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "# Compute probabilities for grid points\n",
    "p_grid = compute_gaussian_probability(grid_points, mu, sigma2)\n",
    "p_grid = p_grid.reshape(xx.shape)\n",
    "\n",
    "# Plot decision boundary\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.contourf(xx, yy, p_grid, levels=np.linspace(0, np.max(p_grid), 20), cmap='viridis', alpha=0.3)\n",
    "plt.colorbar(label='Probability Density')\n",
    "\n",
    "# Plot data points\n",
    "plt.scatter(normal_data[:, 0], normal_data[:, 1], alpha=0.5, label='Normal Data')\n",
    "plt.scatter(anomalies[:, 0], anomalies[:, 1], c='red', alpha=0.7, label='True Anomalies')\n",
    "\n",
    "# Plot threshold contour\n",
    "plt.contour(xx, yy, p_grid, levels=[epsilon], colors='r', linestyles='dashed', linewidths=2)\n",
    "\n",
    "plt.title('Anomaly Detection Results')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
